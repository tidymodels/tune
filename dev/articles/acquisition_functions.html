<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Acquisition functions • tune</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Source_Sans_Pro-0.4.9/font.css" rel="stylesheet">
<link href="../deps/Source_Code_Pro-0.4.9/font.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Acquisition functions">
<meta name="description" content="What are acquisition functions? Learn how are they used to guide the
exploration of the parameter space during Bayesian optimization.
">
<meta property="og:description" content="What are acquisition functions? Learn how are they used to guide the
exploration of the parameter space during Bayesian optimization.
">
<meta property="og:image" content="https://tune.tidymodels.org/logo.png">
<meta name="robots" content="noindex">
<script defer data-domain="tune.tidymodels.org,all.tidymodels.org" src="https://plausible.io/js/plausible.js"></script>
</head>
<body>
    <a href="#container" class="visually-hidden-focusable">Skip to content</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-none" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">tune</a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">1.3.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/tune.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/acquisition_functions.html">Acquisition functions</a></li>
    <li><a class="dropdown-item" href="../articles/extras/optimizations.html">Optimizations and parallel processing</a></li>
  </ul>
</li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-learn-more" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Learn more</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-learn-more">
<li><a class="external-link dropdown-item" href="https://www.tidymodels.org/learn/work/tune-svm/">Grid search</a></li>
    <li><a class="external-link dropdown-item" href="https://www.tidymodels.org/learn/work/bayes-opt/">Bayesian optimization of classification model</a></li>
    <li><a class="external-link dropdown-item" href="https://www.tidymodels.org/learn/work/tune-text/">Tuning text models</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/tidymodels/tune/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article" id="container">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Acquisition functions</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/tidymodels/tune/blob/main/vignettes/acquisition_functions.Rmd" class="external-link"><code>vignettes/acquisition_functions.Rmd</code></a></small>
      <div class="d-none name"><code>acquisition_functions.Rmd</code></div>
    </div>

    
    
<p><em>Acquisition functions</em> are mathematical techniques that guide
how the parameter space should be explored during Bayesian optimization.
They use the predicted mean and predicted variance generated by the
Gaussian process model. For a set of such predictions on a set of
candidate parameter sets, an acquisition functions combines the means
and variances into a criterion that will direct the search.</p>
<p>The variance term that is generated by the Gaussian process model
usually reflects the spatial aspects of the data. Candidate sets with
high variance are not near any existing parameter values (i.e. those
that have observed performance estimates). The predicted variance is
very close to zero at or very near to an existing result.</p>
<p>There is usually a trade-off between two strategies:</p>
<ul>
<li><p><em>exploitation</em> focuses on results in the vicinity of the
current best results by penalizing for higher variance values.</p></li>
<li><p><em>exploration</em> pushes the search towards unexplored
regions.</p></li>
</ul>
<p>The acquisition functions themselves have quasi-tuning parameters
that are usually trade-offs between exploitation and exploration. For
example, if the performance measure being used should be maximized
(i.e. accuracy, the area under the ROC curve, etc), then one acquisition
function would be a lower confidence bound
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><mi>μ</mi><mo>−</mo><mi>C</mi><mo>×</mo><mi>σ</mi></mrow><annotation encoding="application/x-tex">L = \mu - C \times \sigma</annotation></semantics></math>.
The multiplier
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math>
would be used to penalize based on the predicted standard error
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>σ</mi><annotation encoding="application/x-tex">\sigma</annotation></semantics></math>)
of different parameter combinations. Note that the acquisition function
is not the performance measure, but a function of what metric is used to
evaluate the model.</p>
<p>One of the most common acquisition functions is the <em>expected
improvement</em>. Based on basic probability theory, this can be
computed relative to the current estimate of the optimal performance.
Suppose that our performance metric should be maximized (e.g. accuracy,
area under the ROC curve, etc). For any tuning parameter combination
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>θ</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>,
we have the predicted mean and standard error of that metric (call those
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mu(\theta)</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\sigma(\theta)</annotation></semantics></math>).
From previous data, the best (mean) performance value was
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>m</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub><annotation encoding="application/x-tex">m_{opt}</annotation></semantics></math>).
The expected improvement is determined using:</p>
<p><span class="math display">$$
\begin{align}
EI(\theta; m_{opt}) &amp;= \delta(\theta)
\Phi\left(\frac{\delta(\theta)}{\sigma(\theta)}\right) + \sigma(\theta)
\phi\left(\frac{\delta(\theta)}{\sigma(\theta)}\right) \notag \\
&amp;\text{where} \notag \\
\delta(\theta) &amp;= \mu(\theta) - m_{opt} \notag
\end{align}
$$</span></p>
<p>The function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Φ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>⋅</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\Phi(\cdot)</annotation></semantics></math>
is the cumulative standard normal and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>⋅</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\phi(\cdot)</annotation></semantics></math>
is the standard normal density.</p>
<p>The value
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\delta(\theta)</annotation></semantics></math>
measures how close we are (on average) to the current best performance
value<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;This equation treats
&lt;math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;msub&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;annotation encoding="application/x-tex"&gt;m_{opt}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;
as if it has no variation and no correlation to
&lt;math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;μ&lt;/mi&gt;&lt;mrow&gt;&lt;mo stretchy="true" form="prefix"&gt;(&lt;/mo&gt;&lt;mi&gt;θ&lt;/mi&gt;&lt;mo stretchy="true" form="postfix"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;\mu(\theta)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;.
Neither of those are true so consider this a “first order approximation”
instead of a highly accurate estimate.&lt;/p&gt;'><sup>1</sup></a>.
When new candidate tuning parameters are needed, the space of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>θ</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
is searched for the value that maximizes the expected improvement.</p>
<p>Suppose a single parameter were being optimized and that parameter
was represented using a log10 transformation. Using resampling, suppose
the accuracy results for three points were evaluated:</p>
<p><img src="figures%2Finitial.svg" alt="A ggplot2 dot plot. The x axis is labeled Parameter, with values ranging from .01 to 1 on a log scale, and accuracy values are plotted on the y axis. There are three dots, with no immediately discernible trend."></p>
<p>In the first iteration of Bayesian optimization, these three data
points are given to the Gaussian process model to produce predictions
across a wider range of values. The fitted curve
(i.e. <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mu(\theta)</annotation></semantics></math>)
is shown on the top panel below, along with approximate 95% credible
intervals
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>±</mo><mn>1.96</mn><mi>σ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mu(\theta) \pm 1.96 \sigma(\theta)</annotation></semantics></math>:</p>
<p><img src="figures%2Fiter_1.svg" alt="A ggplot line plot. The data are the same as that plotted above, but a curved line is plotted over the points, now. A shaded region, representing a confidence band, grows wider as the distance in the x axis from an observed parameter value increases. An additional panel is shown below the plot, where a measure called Expected Improvement is plotted on the y axis."></p>
<p>Notice that the interval width is large in regions far from observed
data points.</p>
<p>The bottom panel shows the expected improvement across the range of
candidate values. Of the observed points, the expected improvement near
the middle point has the largest improvement. This is because the first
term in the equation above (with the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\delta(\theta)</annotation></semantics></math>
coefficient) is very large while the second term (with the coefficient
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\sigma(\theta)</annotation></semantics></math>
is virtually zero. This focus on the mean portion will keep the search
mostly in the region of the best performance.</p>
<p>Using these results, the parameter value with the largest improvement
is then evaluated using cross-validation. The GP model is then updated
and a new parameter is chosen and so on.</p>
<p>The results at iteration 20 were:</p>
<p><img src="figures%2Fiter_20.svg" alt="A ggplot2 dot plot much like the one above, except that an additional 17 points are now plotted. The confidence bands around the newly drawn line are much tighter. The expected improvement reaches higher values only in a much smaller portion of the x axis, now."></p>
<p>The points shown on the graph indicate that there is a region in the
neighborhood of 0.01 that appears to produce the best results, and that
the expected improvement function has driven the optimization to focus
on this region.</p>
<p>When using expected improvement, the primary method for compromising
between exploitation and exploration is the use of a “trade-off” value.
This value is the amount of performance (in the original units) that can
be sacrificed when computing the improvement. This has the effect of
down-playing the contribution of the mean effect in the computations.
For a trade-off value
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>,
the equation above uses:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>μ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><msub><mi>m</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub><mo>−</mo><mi>τ</mi></mrow><annotation encoding="application/x-tex">
\delta(\theta) = \mu(\theta) - m_{opt} - \tau
</annotation></semantics></math></p>
<p>Suppose that we were willing to trade-off
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">\tau = 0.05</annotation></semantics></math>%
of the predicted accuracy during the search. Using the same three
initial results, the procedure would end up in the same general location
but would have explored more values across the total range:</p>
<p><img src="figures%2Ftrade_off_20.svg" alt="A plot identical to the one above, though generated with a different parameter value for the trade-off. The expected improvement, in the bottom pane, is nearly always zero, with one narrow section remaining of positive value."></p>
<p>There are two main strategies for <em>dynamic trade-offs</em> during
the optimization:</p>
<ul>
<li><p>Use a function to specify the parameter(s) for the acquisition
functions. For expected improvement, this can be done using
<code>exp_improve(trade_off = foo())</code>. <code>foo()</code> should
be a function whose first parameter is the current iteration number.
When tune invokes this function, only the first argument is used. A good
strategy might be to set <code>trade_off</code> to some non-zero value
at the start of the search and incrementally approach zero after a
reasonable period.</p></li>
<li><p><code><a href="../reference/control_bayes.html">control_bayes()</a></code> has an option for doing an
additional <em>uncertainty sample</em> when no improvements have been
found. This is a technique from the active learning literature where new
data points are sampled that most help the model. In this case, the
candidate points are scored only on variance and a candidate is chosen
from a set of the <em>most</em> variable design points. This may find a
location in the parameter space to help the optimization make
improvements.</p></li>
</ul></main>
</div>



   </div>
  <footer><div class="container">
  <div class="pkgdown-footer-left">
  <p>Developed by <a href="https://github.com/topepo" class="external-link">Max Kuhn</a>, <a href="https://www.posit.co" class="external-link"><img src="https://www.tidyverse.org/posit-logo.svg" alt="Posit" height="16" width="62" style="margin-bottom: 3px;"></a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

  </div></footer>
</body>
</html>
